{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten Recognition using TensorFlow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshutoshAgrahari/GoogleColab/blob/master/Handwritten_Recognition_using_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4LkYcqU08wtr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Handwritten Recognition using TensorFlow\n",
        "\n",
        "Rrf: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%202%20-%20Handwriting%20Recognition/Exercise2-Question.ipynb\n",
        "\n",
        "MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "Building an MNIST classifier in tensorflow that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. the training should stop once it reaches that level of accuracy.\n",
        "\n",
        "Some notes:\n",
        "\n",
        "1. It should succeed in less than 10 epochs, so it is okay to change epochs to 10, but nothing larger\n",
        "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
        "3. If you add any additional variables, make sure you use the same names as the ones used in the class"
      ]
    },
    {
      "metadata": {
        "id": "XNlUulcu8k2F",
        "colab_type": "code",
        "outputId": "a04a7168-d5b2-4815-afdc-e616d6834858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "# Loading the library\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Loading the mnist handwritten dataset form keras datasets.\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# extracting training and testing images and labels\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Checking the dimension of x_train dataset\n",
        "# np.shape(x_train)\n",
        "\n",
        "# Printing digit grey scale image code and handwritten number details as labels\n",
        "# print(x_train[0])\n",
        "# print(y_train[0])\n",
        "\n",
        "# Normalizing the data from current scale of 0-255 to 0-1\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "# creating callback class which has on_epoch_end function to stop running multiple epochs when training reaches 99% accuracy.\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.99):\n",
        "      print(\"\\nReached 99% accuracy, so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "\n",
        "# creating object of myCallback class to call the function      \n",
        "callbacks = myCallback()\n",
        "\n",
        "# Building Neural Network model by\n",
        "# 1. Flating the matrix data in vector in 1st layer as input layer\n",
        "# 2. creating 512 neuron in 2nd layer which will pass the data only which is greater than or equal to 0.\n",
        "# 3. Output layer will have 10 neurons, each for one digit which is equal to number of labels.\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape =(28, 28)),\n",
        "                                   tf.keras.layers.Dense(512, activation= tf.nn.relu),\n",
        "                                   tf.keras.layers.Dense(10, activation= tf.nn.softmax)\n",
        "                                   ])\n",
        "\n",
        "# setting the optimizer, loss and metric.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# training the model with training dataset.\n",
        "model.fit(x_train, y_train, epochs = 10, callbacks =[callbacks])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 18s 298us/sample - loss: 0.1991 - acc: 0.9419\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 17s 287us/sample - loss: 0.0796 - acc: 0.9754\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 17s 286us/sample - loss: 0.0534 - acc: 0.9830\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 18s 294us/sample - loss: 0.0375 - acc: 0.9883\n",
            "Epoch 5/10\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9913\n",
            "Reached 99% accuracy, so cancelling training!\n",
            "60000/60000 [==============================] - 18s 295us/sample - loss: 0.0271 - acc: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f88567029b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "IfKJDgty3n6E",
        "colab_type": "code",
        "outputId": "9708de78-3cec-4507-c341-b2cbfff547a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# Validating the Model with Test data\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 66us/sample - loss: 0.0661 - acc: 0.9818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06611347748858389, 0.9818]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "ZV_VsUJH4DNr",
        "colab_type": "code",
        "outputId": "844f752a-218b-4193-feeb-949c42d3997d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#prevent numpy exponential \n",
        "#notation on print, default False\n",
        "#import numpy as np\n",
        "#np.set_printoptions(suppress = True)\n",
        "\n",
        "#classification = model.predict(x_test)\n",
        "i = 500\n",
        "if(np.argmax(np.array(classification[i])) == y_test[i]):\n",
        "  print(\"\\nRight Prediction\")\n",
        "else:\n",
        "  print(\"\\nWrong Prediction\")\n",
        "print(np.argmax(np.array(classification[i])))\n",
        "\n",
        "#print(classification[0])\n",
        "#print(y_test[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Right Prediction\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sx6btdVbzmro",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exercise 3:\n",
        "\n",
        "Ref: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%203%20-%20Convolutions/Exercise%203%20-%20Question.ipynb\n",
        "\n",
        "It is required to implement Convolution layer for detect the hand written image recogition neural network using tensor flow. \n",
        "\n",
        "we need make sue few thing and use parameter as:\n",
        "\n",
        "1. Accuracy needs to achieve till 99.8%.\n",
        "\n",
        "2. Maximum 20 epochs can be used to building CNN.\n",
        "\n",
        "3. Callbacks needs to call to early stopping the model training once model accuracy reached 99.8%.\n",
        "\n",
        "4. Single or more convolution layer or MaxPolling2D layer can be used to get the result in lesser time with lesser number of epochs.\n",
        "\n",
        "Before running the convolution NN in tensor flow, please select in GPU as hardware accelerator in change runtime type under Runtime."
      ]
    },
    {
      "metadata": {
        "id": "7rkhyXgxzyUx",
        "colab_type": "code",
        "outputId": "c8299f7f-3338-46a9-c2ae-95ba0a117c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "cell_type": "code",
      "source": [
        "# Loading the library\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Loading the mnist handwritten dataset form keras datasets.\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# extracting training and testing images and labels\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(60000,28,28,1)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "x_test = x_test/255.0\n",
        "\"\"\"\n",
        "# creating callback class which has on_epoch_end function to stop running multiple epochs when training reaches 99.8% accuracy.\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.998):\n",
        "      print(\"\\nReached 99% accuracy, so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "\n",
        "# creating object of myCallback class to call the function      \n",
        "callbacks = myCallback()\n",
        "\n",
        "# Building Neural Network model with convolution filter and MaxPooling2D by\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape = (28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation= tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation= tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# setting the optimizer, loss and metric.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# training the model with training dataset.\n",
        "model.fit(x_train, y_train, epochs = 20, callbacks =[callbacks])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(test_acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.1533 - acc: 0.9522\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 15s 258us/sample - loss: 0.0511 - acc: 0.9840\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 16s 266us/sample - loss: 0.0345 - acc: 0.9889\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 16s 260us/sample - loss: 0.0261 - acc: 0.9916\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 16s 262us/sample - loss: 0.0191 - acc: 0.9940\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.0163 - acc: 0.9945\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 15s 255us/sample - loss: 0.0130 - acc: 0.9957\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 16s 261us/sample - loss: 0.0108 - acc: 0.9964\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 16s 260us/sample - loss: 0.0089 - acc: 0.9973\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 16s 261us/sample - loss: 0.0079 - acc: 0.9976\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 15s 258us/sample - loss: 0.0068 - acc: 0.9977\n",
            "Epoch 12/20\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9980\n",
            "Reached 99% accuracy, so cancelling training!\n",
            "60000/60000 [==============================] - 16s 259us/sample - loss: 0.0068 - acc: 0.9980\n",
            "10000/10000 [==============================] - 1s 116us/sample - loss: 0.0571 - acc: 0.9873\n",
            "0.9873\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}